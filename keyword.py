from kafka import KafkaConsumer
import json
from keybert import KeyBERT
from konlpy.tag import Okt

# Kafka Consumer ì„¤ì •
consumer = KafkaConsumer(
    "voc-json",
    bootstrap_servers="localhost:9092",
    auto_offset_reset="latest",
    enable_auto_commit=True,
    group_id="analyzer-group",
    value_deserializer=lambda x: json.loads(x.decode("utf-8"))
)

# í‚¤ì›Œë“œ ì¶”ì¶œê¸° ë° í˜•íƒœì†Œ ë¶„ì„ê¸°
kw_model = KeyBERT()
okt = Okt()

# í˜•íƒœì†Œ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ëª…ì‚¬ ì¶”ì¶œ)
def preprocess_korean(text):
    tokens = okt.nouns(text)
    return " ".join(tokens)

print("ğŸ” Kafka í•œêµ­ì–´ ë¶„ì„ ì„œë²„ ì‹¤í–‰ ì¤‘...")

for message in consumer:
    data = message.value
    text = data.get("consulting_content", "")
    category = data.get("consulting_category", "")

    if not isinstance(text, str) or not text.strip():
        print("âš ï¸ consulting_content í•„ë“œê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŒ. ìŠ¤í‚µ.")
        continue

    print("\nğŸ“© ìˆ˜ì‹ ëœ ë©”ì‹œì§€ ë‚´ìš©:")
    print(text)

    # âœ… í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤í–‰ (ì¹´í…Œê³ ë¦¬ í¬í•¨)
    try:
        combined_text = f"{category} {text}"
        preprocessed_text = preprocess_korean(combined_text)
        keywords = kw_model.extract_keywords(preprocessed_text, top_n=5)
        keywords = [kw[0] for kw in keywords]
        print("ğŸ”‘ í‚¤ì›Œë“œ:", keywords)
    except Exception as e:
        print(f"âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
